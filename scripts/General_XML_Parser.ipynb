{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Post_Contact_inhibition_1_Tracks.xml', 'Post_Contact_inhibition_2_Tracks.xml', 'Post_Contact_inhibition_3_Tracks.xml', 'Post_Contact_inhibition_4_Tracks.xml', 'Post_Contact_inhibition_5_Tracks.xml']\n",
      "0\n",
      "(60, 11307, 2)\n",
      "./NPYs/Kevin_After/npy_000.npy\n",
      "1\n",
      "(60, 12155, 2)\n",
      "./NPYs/Kevin_After/npy_001.npy\n",
      "2\n",
      "(60, 11733, 2)\n",
      "./NPYs/Kevin_After/npy_002.npy\n",
      "3\n",
      "(60, 12660, 2)\n",
      "./NPYs/Kevin_After/npy_003.npy\n",
      "4\n",
      "(60, 12596, 2)\n",
      "./NPYs/Kevin_After/npy_004.npy\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Options: 'h_bulk'=HUVECs, 'mdck'=MDCKs, 'mda_bulk'=MDA-MB-231s\n",
    "cell_type = 'mdck_kevin'\n",
    "\n",
    "# Options: 0 or 1\n",
    "do_subsample = 0\n",
    "subsample_step = 2\n",
    "\n",
    "# Options: 0 or 1\n",
    "do_timerange = 0\n",
    "num_hours = 6*8*2\n",
    "start_frame = 6*8\n",
    "end_frame = start_frame + num_hours\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "if(cell_type=='h_bulk'):\n",
    "    file_path_xml = './XMLs/HUVEC_Bulk'\n",
    "    file_path_npy = './NPYs/HUVEC_Bulk'\n",
    "    frame_range = 140\n",
    "    frames_per_hour = 6.0\n",
    "    blob_size = 12.0\n",
    "    body_size = 25.0\n",
    "    \n",
    "if(cell_type=='h_bulk_cut'):\n",
    "    file_path_xml = './XMLs/HUVEC_Bulk'\n",
    "    file_path_npy = './NPYs/HUVEC_Bulk_46'\n",
    "    frame_range = 140\n",
    "    frames_per_hour = 6.0\n",
    "    blob_size = 12.0\n",
    "    body_size = 25.0\n",
    "    \n",
    "if(cell_type=='mdck_bulk'):\n",
    "    file_path_xml = './XMLs/MDCK_Bulk'\n",
    "    file_path_npy = './NPYs/MDCK_Bulk'\n",
    "    frame_range = 49\n",
    "    frames_per_hour = 6.0\n",
    "    blob_size = 15.0\n",
    "    body_size = 35.0\n",
    "    \n",
    "if(cell_type=='mdck_edge'):\n",
    "    file_path_xml = './XMLs/MDCK_Edge'\n",
    "    file_path_npy = './NPYs/MDCK_Edge'\n",
    "    frame_range = 49\n",
    "    frames_per_hour = 6.0\n",
    "    blob_size = 15.0\n",
    "    body_size = 35.0\n",
    "    \n",
    "if(cell_type=='mda_bulk'):\n",
    "    file_path_xml = './XMLs/MDA_MB_231_Bulk'\n",
    "    file_path_npy = './NPYs/MDA_MB_231_Bulk'\n",
    "    frame_range = 97\n",
    "    frames_per_hour = 6.0\n",
    "    blob_size = 15.0\n",
    "    body_size = 35.0    \n",
    "    \n",
    "if(cell_type=='mdck_kevin'):\n",
    "    file_path_xml = './XMLs/Kevin_After'\n",
    "    file_path_npy = './NPYs/Kevin_After'\n",
    "    frame_range = 60\n",
    "    frames_per_hour = 3.0\n",
    "    blob_size = 6.0\n",
    "    body_size = 15.0\n",
    "    \n",
    "if(do_subsample==1):\n",
    "    file_path_npy = file_path_npy + '_Subsample_' + str(subsample_step) \n",
    "if(do_timerange==1):\n",
    "    file_path_npy = file_path_npy + '_TimeRange_' + str(start_frame) + '_' + str(end_frame) \n",
    "if not os.path.exists(file_path_npy):\n",
    "    os.makedirs(file_path_npy)\n",
    "\n",
    "#---------------------------------------------------------------------------------------------#\n",
    "\n",
    "# Get all XML files in that path: \n",
    "file_list = [f for f in os.listdir(file_path_xml) if os.path.isfile(os.path.join(file_path_xml, f)) and f.endswith('.xml')]\n",
    "file_list.sort()\n",
    "print(file_list)\n",
    "\n",
    "# Loop over XML files (each representing one tissue):\n",
    "for i in range(len(file_list)):\n",
    "    \n",
    "    print(i)\n",
    "        \n",
    "    # Get the XML filename: \n",
    "    filename = file_path_xml + '/' + file_list[i]\n",
    "    \n",
    "    # Use library to parse XML file: \n",
    "    root = ET.parse(filename).getroot()\n",
    "            \n",
    "    # Empty initial array for storing trajectories: \n",
    "    trajectories = np.empty([len(root.findall('particle')), frame_range, 2])\n",
    "        \n",
    "    # Loop over all tracks: \n",
    "    counter = 0\n",
    "    for type_tag in root.findall('particle'):\n",
    "        #if(type_tag.get('nSpots')!=str(frame_range)):\n",
    "        #    print(type_tag.get('nSpots'))\n",
    "        #    print(i)\n",
    "        #    print('Error')\n",
    "        #    break\n",
    "            \n",
    "        # Get x, y trajectory values for each individual track: \n",
    "        x_store = []\n",
    "        y_store = []\n",
    "        for detection in type_tag:\n",
    "            x_store.append(detection.get('x'))\n",
    "            y_store.append(detection.get('y'))\n",
    "            \n",
    "        #print(len(x_store))\n",
    "        #print(len(y_store))\n",
    "        \n",
    "        #print(counter)\n",
    "            \n",
    "        # Add trajectories to numpy array containing ALL tracks: \n",
    "        xtraj_temp = np.asarray(x_store) #, dtype=np.float32)\n",
    "        ytraj_temp = np.asarray(y_store)\n",
    "        traj_temp = np.empty([frame_range, 2])\n",
    "        \n",
    "        if(len(xtraj_temp) == frame_range):\n",
    "            traj_temp[:,0] = xtraj_temp\n",
    "            traj_temp[:,1] = ytraj_temp\n",
    "        \n",
    "            trajectories[counter,:,:] = traj_temp\n",
    "            counter += 1\n",
    "        \n",
    "    traj_store = trajectories[:(counter-1), :, :]\n",
    "    \n",
    "    traj_store_real = np.transpose(traj_store, (1, 0, 2))\n",
    "    print(traj_store_real.shape)\n",
    "    \n",
    "    if(do_timerange==1):\n",
    "        traj_store_real = traj_store_real[start_frame:end_frame, :, :]\n",
    "        #traj_store_real = traj_store_real[start_frame:, :, :]\n",
    "\n",
    "        print(traj_store_real.shape)\n",
    "    if(do_subsample==1):\n",
    "        traj_store_real = traj_store_real[::subsample_step, :, :]\n",
    "        print(traj_store_real.shape)\n",
    "    \n",
    "                \n",
    "    # ----------------------------------------------------------------    \n",
    "    # Save data for EACH video now: \n",
    "    cells =\t{\n",
    "      'frames_per_second': frames_per_hour,\n",
    "      'video_path': \"All\",\n",
    "      'trajectories': traj_store_real,\n",
    "        'git_commit': 'None\\n', \n",
    "        'body_lenght': body_size, \n",
    "        'body_lentgh': body_size, \n",
    "        'body_length': body_size\n",
    "    }\n",
    "\n",
    "    save_traj_name = file_path_npy + '/npy_' + str(i).zfill(3) + '.npy'\n",
    "    print(save_traj_name)\n",
    "    np.save(save_traj_name, cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import random\n",
    "\n",
    "# If you wanna do the test/train split here:\n",
    "\n",
    "num_in_training_set = 10\n",
    "\n",
    "file_list = [f for f in os.listdir(file_path_npy) if os.path.isfile(os.path.join(file_path_npy, f)) and f.endswith('.npy')]\n",
    "file_list.sort()\n",
    "print(file_list)\n",
    "\n",
    "train_dir = file_path_npy + '/train'\n",
    "test_dir = file_path_npy + '/test'\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "    \n",
    "num_files = len(file_list)\n",
    "\n",
    "random.seed(42)\n",
    "random_inds = random.sample((np.arange(len(file_list)).tolist()), num_in_training_set)\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    \n",
    "    # Get the NPY filename: \n",
    "    old_filename = file_path_npy + '/' + file_list[i]\n",
    "    \n",
    "    # Training or test set? \n",
    "    if(i in random_inds):\n",
    "        new_filename = train_dir + '/' + file_list[i]\n",
    "    else:\n",
    "        new_filename = test_dir + '/' + file_list[i]\n",
    "    shutil.move(old_filename, new_filename)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
